{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Лабораторная на Классификацию ||\n",
    "\n",
    "В ходе этой работы мы проведём классификацию на реальных данных при помощи логистической регрессии"
   ],
   "id": "37eb7f9aa931e3f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Импортируем библиотеки",
   "id": "8d14397d4fe84f01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T23:58:43.038550Z",
     "start_time": "2025-12-27T23:58:43.033875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score"
   ],
   "id": "86da16b84e77f95f",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Получим данные и сразу их предобработаем (данные не отличаются от блокнота 1_2 - тот же набор, соответственно весь анализ был уже проведён)",
   "id": "b574d3e938d37ee5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T23:05:42.872611Z",
     "start_time": "2025-12-27T23:05:42.717938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('./data/bank-additional-full.csv', sep=';')\n",
    "\n",
    "# Разделим данные на категориальные и числовые\n",
    "numerical_cols = ['age', 'duration', 'campaign', 'pdays', 'previous',\n",
    "                  'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
    "                  'euribor3m', 'nr.employed']\n",
    "categorical_cols = ['job', 'marital', 'education', 'default', 'housing',\n",
    "                    'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "\n",
    "# Обработаем пропуски и заменим 'unknown' на наиболее частое значение\n",
    "for col in categorical_cols:\n",
    "    if (df[col] == 'unknown').sum() > 0:\n",
    "        mode_value = df[col][df[col] != 'unknown'].mode()[0]\n",
    "        df[col] = df[col].replace('unknown', mode_value)\n",
    "\n",
    "# Проведём One-Hot кодирование для категориальных признаков\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Стандартизируем числовые признаки\n",
    "scaler = StandardScaler()\n",
    "df_encoded[numerical_cols] = scaler.fit_transform(df_encoded[numerical_cols])"
   ],
   "id": "f110e59dad9aa871",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Обучим базовую модель логистической регрессии",
   "id": "37b51c682b0c1ff9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T23:25:01.105142Z",
     "start_time": "2025-12-27T23:25:00.968850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Разделение на признаки и целевую переменную\n",
    "X_numerical = df_encoded[numerical_cols]\n",
    "y = df['y']\n",
    "\n",
    "# Разделим на train/test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_numerical, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Создадим baseline логистической регрессии на числовых признаках\n",
    "baseline_model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=2000,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "baseline_model.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = baseline_model.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test, Y_pred))\n"
   ],
   "id": "3ba05b5969df978c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.98      0.85      0.91      7310\n",
      "         yes       0.43      0.89      0.58       928\n",
      "\n",
      "    accuracy                           0.85      8238\n",
      "   macro avg       0.71      0.87      0.75      8238\n",
      "weighted avg       0.92      0.85      0.87      8238\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "У нас вышел сильный дисбаланс классов (отказов куда больше, нежели положительных результатов), а так же низкая точность для \"yes\" - когда модель предсказывать \"yes\", то ошибается БОЛЕЕ ЧЕМ НА 50% (это критично) (модель жертвует точностью ради полноты). Но в целом после обучения на числовых признаках мы получили неплохие результаты, теперь можно улучшать модельку дальше (в частности разобраться с низким precision для \"yes\")",
   "id": "fc5cb1ee24e07686"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Улучшим качество модели",
   "id": "63e55956cb9178d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Давайте попробуем убрать балансировку и поработаем с некоторыми категориальными признаками",
   "id": "889151341f2d3d84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T23:25:09.634474Z",
     "start_time": "2025-12-27T23:25:09.015310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Проверим разные веса и выберем подходящий\n",
    "for weight_yes in [1, 2, 3, 4, 5, 6]:\n",
    "    new_baseline_model = LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=2000,\n",
    "        class_weight={'no': 1, 'yes': weight_yes}\n",
    "    )\n",
    "    new_baseline_model.fit(X_train, Y_train)\n",
    "\n",
    "    y_pred = new_baseline_model.predict(X_test)\n",
    "    print(f\"Weight yes = {weight_yes}\")\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "    print(\"------------------------------------------------------\")"
   ],
   "id": "2a11c6e5d2bfb2f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight yes = 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.98      0.95      7310\n",
      "         yes       0.69      0.39      0.50       928\n",
      "\n",
      "    accuracy                           0.91      8238\n",
      "   macro avg       0.81      0.68      0.72      8238\n",
      "weighted avg       0.90      0.91      0.90      8238\n",
      "\n",
      "------------------------------------------------------\n",
      "Weight yes = 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.95      0.95      0.95      7310\n",
      "         yes       0.61      0.58      0.59       928\n",
      "\n",
      "    accuracy                           0.91      8238\n",
      "   macro avg       0.78      0.77      0.77      8238\n",
      "weighted avg       0.91      0.91      0.91      8238\n",
      "\n",
      "------------------------------------------------------\n",
      "Weight yes = 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.96      0.93      0.95      7310\n",
      "         yes       0.56      0.69      0.62       928\n",
      "\n",
      "    accuracy                           0.90      8238\n",
      "   macro avg       0.76      0.81      0.78      8238\n",
      "weighted avg       0.91      0.90      0.91      8238\n",
      "\n",
      "------------------------------------------------------\n",
      "Weight yes = 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.97      0.91      0.94      7310\n",
      "         yes       0.52      0.76      0.62       928\n",
      "\n",
      "    accuracy                           0.89      8238\n",
      "   macro avg       0.75      0.84      0.78      8238\n",
      "weighted avg       0.92      0.89      0.90      8238\n",
      "\n",
      "------------------------------------------------------\n",
      "Weight yes = 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.97      0.89      0.93      7310\n",
      "         yes       0.49      0.80      0.61       928\n",
      "\n",
      "    accuracy                           0.88      8238\n",
      "   macro avg       0.73      0.85      0.77      8238\n",
      "weighted avg       0.92      0.88      0.89      8238\n",
      "\n",
      "------------------------------------------------------\n",
      "Weight yes = 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.98      0.88      0.92      7310\n",
      "         yes       0.46      0.84      0.60       928\n",
      "\n",
      "    accuracy                           0.87      8238\n",
      "   macro avg       0.72      0.86      0.76      8238\n",
      "weighted avg       0.92      0.87      0.89      8238\n",
      "\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "По метрикам разных весов мы видим, что как будто бы модель при 3 ведёт себя интереснее, нежели другие и базовая модель",
   "id": "363892345309e2e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T23:27:31.051351Z",
     "start_time": "2025-12-27T23:27:30.759321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Добавим категориальные признаки, обучим модель и посмотрим что вышло\n",
    "X_full = df_encoded.drop('y', axis=1)\n",
    "y = df['y']\n",
    "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(\n",
    "    X_full, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "model_full = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=2000,\n",
    "    class_weight={'no': 1, 'yes': 3}\n",
    ")\n",
    "model_full.fit(X_train_f, y_train_f)\n",
    "\n",
    "y_pred_f = model_full.predict(X_test_f)\n",
    "print(classification_report(y_test_f, y_pred_f))"
   ],
   "id": "4e2cb65bedb694fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.97      0.93      0.95      7310\n",
      "         yes       0.57      0.74      0.65       928\n",
      "\n",
      "    accuracy                           0.91      8238\n",
      "   macro avg       0.77      0.84      0.80      8238\n",
      "weighted avg       0.92      0.91      0.91      8238\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "При использовании категориальных признаков наша модель стала \"умнее\" по одним метрикам, либо не стала \"тупее\" по другим - это очень хорошо (не ушли в минус, значит улучшили). Можно было бы более умно обработать признаки, провести Future engineering, посмотреть корреляции признаков и это использовать, а так же углубиться в домен и понять что лучше переиспользовать, но здесь проводить это не будем (ТЗ попытаться улучшить выполнено (даже выполнено с отличием, тк мы попытались и у нас вышло)).",
   "id": "f36d690348856428"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Вывод (серединный)\n",
    "В ходе работы мы обучили модельку на числовых признаках, немного поигрались с параметрами модельки и выбрали лучший, а после дообучили (переучили) на категориальных признаках (использовав только One-Hot кодирование). В целом вышла модель выше 50% по всем метрикам, но опять же проблемы с yes - моделька слишком плохо работает с этим признаком и надо что-то с этим делать (мы попытались и даже улучшили, но нужно применять более умные вещи, описанные выше). Считаю первую работу (выполненную на реальных данных) на классификацию вполне успешной."
   ],
   "id": "eb1d512bbdac3878"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Давайте теперь поработаем с другой моделью и сравним метрики",
   "id": "31a43cec45cad840"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Выберем из 3 предложенных моделей (ближайшие соседи, деревья решений, метод опорных векторов) лучшую. Этой моделью станет Decision Tree, тк она будет лучше работать с дисбалансом, нежели остальные модели (идеальным вариантом тут бы был случайный лес, но его запретили юзать - грусть печаль тоска апатия слёзы и депрессия в 0 лет)",
   "id": "79f86fd94ee0bdf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Создадим базовое дерево, обучим на всех данных и посмотрим метрики",
   "id": "927adc4851e61384"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-27T23:55:34.126246Z",
     "start_time": "2025-12-27T23:55:33.877343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_tree = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "base_tree.fit(X_train_f, y_train_f)\n",
    "\n",
    "y_pred_tree = base_tree.predict(X_test_f)\n",
    "\n",
    "print(classification_report(y_test_f, y_pred_tree))"
   ],
   "id": "e3d205618b919b9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.94      0.94      0.94      7310\n",
      "         yes       0.55      0.54      0.54       928\n",
      "\n",
      "    accuracy                           0.90      8238\n",
      "   macro avg       0.74      0.74      0.74      8238\n",
      "weighted avg       0.90      0.90      0.90      8238\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Вышло лучше базовой логистической регрессии (правда там мы не использовали категориальные данные, но да ладно), теперь нужно поиграться с параметрами, чтобы улучшить наши метрики",
   "id": "f6569bcf7cad527a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-28T00:04:08.335169Z",
     "start_time": "2025-12-28T00:04:05.932908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Используем перебор гипер-параметров дерева и получим лучшую модель\n",
    "scorer = make_scorer(f1_score, pos_label='yes')\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': [3, 5, 7, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10, 20, 50],\n",
    "    'min_samples_leaf': [1, 2, 5, 10, 20],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight': ['balanced', {'no': 1, 'yes': 2}, {'no': 1, 'yes': 3}, {'no': 1, 'yes': 5}, None]\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    dt,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring=scorer,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_f, y_train_f)\n",
    "\n",
    "best_tree = random_search.best_estimator_\n",
    "y_pred_best = best_tree.predict(X_test_f)\n",
    "\n",
    "print(classification_report(y_test_f, y_pred_best))"
   ],
   "id": "b8b4e0600dece6f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.97      0.93      0.95      7310\n",
      "         yes       0.59      0.76      0.66       928\n",
      "\n",
      "    accuracy                           0.91      8238\n",
      "   macro avg       0.78      0.85      0.81      8238\n",
      "weighted avg       0.93      0.91      0.92      8238\n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Здесь мы использовали авто-инструменты, не смотрели на картину логически, это позволило нам не допустить критических ошибок, но и закрыло нам глаза на идеальное решение, которое, возможно, sklearn упустил. Но несмотря на это у нас вышла хорошая модель, которая даже лучше работает, нежели логистическая регрессия (модель даёт хорошие цифры - радостно, соседняя модель такие цифры не накопил - РРРРААААААДОСТНО).\n",
    "P.S. Для выявления лучшей модели мы использовали метрику f-score, тк она помогает нам в целом оценивать модель, а не конкретно полноту или точность, тк модель не должна быть плоха в среднем по всем метрикам."
   ],
   "id": "d55bc226d23376e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Вывод (финальный по сравнению 2 разных моделей классификации)\n",
    "В ходе работы мы обучили 2 разные по типу модели, а так же улучшили их (немного ручками и немного автоматически). Увидели, что для наших данных дерево решений оказалось лучше, тк оно лучше работает с \"yes\" как по точности, так и по полноте (это шикарно), но при этом она работает НЕ ХУЖЕ с \"no\" по любым метрикам! Т.е. для данной задачи и для данных данных нам подходит Дерево решений (если выбирать всего из 2 моделей)."
   ],
   "id": "9bd6916a1b22ffa6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
